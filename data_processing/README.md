# Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze

Repository for the EMNLP 2020 paper ['Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze'](https://www.aclweb.org/anthology/2020.emnlp-main.377/) by Ece Takmaz, Sandro Pezzelle, Lisa Beinborn, Raquel Fern√°ndez.

This subdirectory contains the code we implemented to process the DIDEC data: time-alignment of descriptions in textual form with the audio files, extracting fixation maps from the gaze data(sequential and aggregated), and the alignment of words with the extracted fixation windows.
